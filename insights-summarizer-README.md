# Workflow n8n: insights_summarizer

Workflow automatizado para analizar datos de performance de Meta Ads y generar insights accionables usando LLM.

## üìã Caracter√≠sticas

- ‚úÖ Trigger Cron cada 6 horas o HTTP manual
- ‚úÖ Query a Supabase √∫ltimos 14 d√≠as agrupado por ad/ad_set/campaign
- ‚úÖ LLM analiza y genera: winners, anomal√≠as, oportunidades
- ‚úÖ Detecci√≥n de fatiga de CTR (>25% ca√≠da en 72h)
- ‚úÖ Detecci√≥n de CPA por encima del target
- ‚úÖ Identificaci√≥n de √°ngulos ganadores
- ‚úÖ Insertar en tabla `insights` con evidence JSON
- ‚úÖ Opcional: enviar resumen a Slack

## üöÄ Instalaci√≥n

### 1. Crear la tabla insights en Supabase

Ejecuta el SQL en Supabase SQL Editor:

```sql
-- Ver archivo: insights-table.sql
```

O ejecuta el script directamente desde el archivo incluido.

### 2. Importar el workflow en n8n

1. Abre tu instancia de n8n
2. Ve a **Workflows** ‚Üí **Import from File**
3. Selecciona `n8n-workflow-insights-summarizer.json`
4. Activa el workflow

### 3. Configurar Variables de Entorno

En n8n, ve a **Settings** ‚Üí **Variables** y agrega:

```env
# OpenAI para an√°lisis LLM
OPENAI_API_KEY=sk-...

# Thresholds
CPA_TARGET=50
CTR_FATIGUE_THRESHOLD=25

# Slack (opcional)
SLACK_ENABLED=false
SLACK_CHANNEL=#insights

# Supabase (usar credenciales de conexi√≥n directa Postgres)
# Configurar en credenciales de n8n como Postgres connection
```

### 4. Configurar Credenciales

#### Supabase Postgres
1. Ve a Supabase Dashboard ‚Üí Settings ‚Üí Database
2. Copia la **Connection String** (modo `direct connection`)
3. En n8n, crea credenciales **Postgres**
4. Usa el formato: `postgresql://postgres:[PASSWORD]@[HOST]:5432/postgres`

#### OpenAI API
1. En el nodo **LLM Analyze**, configura:
   - Header: `Authorization: Bearer {{ $env.OPENAI_API_KEY }}`

#### Slack (Opcional)
1. Ve a [Slack Apps](https://api.slack.com/apps)
2. Crea una nueva app o usa una existente
3. Obt√©n el **Bot Token** (OAuth Token)
4. En n8n, crea credenciales **Slack API**
5. Configura `SLACK_ENABLED=true` para habilitar

### 5. Obtener Webhook URL (si usas HTTP trigger)

1. Activa el workflow
2. Copia la URL del webhook desde el nodo **HTTP Trigger**
3. Ejemplo: `https://tu-n8n.com/webhook/insights-summarizer`

## üîß Configuraci√≥n del Workflow

### Cron Schedule

El workflow se ejecuta autom√°ticamente cada 6 horas.

Para cambiar la frecuencia, edita el nodo **Cron Trigger**:
```json
{
  "rule": {
    "interval": [
      {
        "field": "hours",
        "hoursInterval": 6  // Cambiar a 12, 24, etc.
      }
    ]
  }
}
```

### Query a Supabase

El workflow consulta `ads_performance` de los √∫ltimos 14 d√≠as agrupando por:
- **ad**: Por `ad_id` individual
- **ad_set**: Por `campaign_name` (agrupado)
- **campaign**: Por `campaign_name` (agregado)

El query calcula:
- Totales: impressions, clicks, spend, conversions, revenue
- Promedios: CTR, CPA, ROAS
- M√©tricas de fatiga: CTR √∫ltimos 72h vs anteriores 72h

### LLM Analysis

El LLM analiza los datos y genera:

#### Winners
- Top performers por ROAS, CPA o CTR
- Identificados por nivel: ad, ad_set, campaign
- Incluye reasoning y m√©tricas

#### Anomalies
- **CTR Fatigue**: Ca√≠da >25% en CTR en √∫ltimos 72h vs anteriores 72h
- **CPA Above Target**: CPA por encima del target configurado

#### Opportunities
- **Winning Angle**: √Ångulos con mejor ROAS promedio
- **Underperforming Ad Set**: Ad sets con potencial de optimizaci√≥n

### Evidence JSON

Cada insight incluye un campo `evidence` con:
- Datos originales del ad/ad_set/campaign
- M√©tricas calculadas
- Contexto adicional para validaci√≥n

### Slack Integration

Si `SLACK_ENABLED=true`, el workflow env√≠a un resumen a Slack con:
- Contadores de winners, anomalies, opportunities
- Top 3 winners
- Critical anomalies
- Top opportunities

## üìä Estructura de Datos

### Tabla: `insights`

```sql
CREATE TABLE insights (
  id uuid PRIMARY KEY,
  insight_type text NOT NULL,  -- 'winner', 'anomaly', 'opportunity'
  entity_type text,             -- 'ad', 'ad_set', 'campaign'
  entity_id text,
  entity_name text,
  metric text,
  value numeric(10,2),
  threshold numeric(10,2),
  change_percentage numeric(5,2),
  reasoning text,
  evidence jsonb,               -- JSON con datos de evidencia
  priority text,                 -- 'low', 'medium', 'high'
  anomaly_type text,             -- 'ctr_fatigue', 'cpa_above_target'
  opportunity_type text,         -- 'winning_angle', 'underperforming_ad_set'
  angle text,
  recommendation text,
  potential_impact text,
  generated_at timestamp,
  created_at timestamp,
  updated_at timestamp
);
```

## üß™ Testing

### Test Manual
1. Desactiva el **Cron Trigger**
2. Haz clic en **Execute Workflow**
3. Revisa los resultados en cada nodo:
   - Query Supabase debe devolver datos
   - LLM debe generar insights estructurados
   - Insert debe completarse sin errores

### Test HTTP Trigger

```bash
curl -X POST https://tu-n8n.com/webhook/insights-summarizer \
  -H "Content-Type: application/json"
```

### Verificar Datos

```sql
-- Ver √∫ltimos insights generados
SELECT insight_type, entity_name, metric, value, priority, generated_at
FROM insights
ORDER BY generated_at DESC
LIMIT 20;

-- Ver winners recientes
SELECT entity_name, metric, value, reasoning
FROM insights
WHERE insight_type = 'winner'
ORDER BY generated_at DESC
LIMIT 10;

-- Ver anomal√≠as cr√≠ticas
SELECT entity_name, anomaly_type, metric, value, threshold, change_percentage
FROM insights
WHERE insight_type = 'anomaly'
  AND priority = 'high'
ORDER BY generated_at DESC;

-- Ver oportunidades de √°ngulos
SELECT angle, recommendation, potential_impact
FROM insights
WHERE insight_type = 'opportunity'
  AND opportunity_type = 'winning_angle'
ORDER BY generated_at DESC;
```

## üîç Troubleshooting

### Error: "No data returned from Supabase"
- Verifica que existan datos en `ads_performance` de los √∫ltimos 14 d√≠as
- Revisa la conexi√≥n a Supabase Postgres
- Verifica que el query SQL sea correcto

### Error: "LLM Analysis failed"
- Verifica que `OPENAI_API_KEY` est√© configurado
- Revisa rate limits de OpenAI
- Verifica que el modelo est√© disponible
- Los datos pueden ser muy grandes; considera limitar el tama√±o del payload

### Error: "CTR Fatigue not detected"
- Verifica que existan datos de los √∫ltimos 72h
- Verifica que el c√°lculo de `ctr_last_72h` y `ctr_previous_72h` sea correcto
- Ajusta el threshold `CTR_FATIGUE_THRESHOLD` si es necesario

### Error: "Slack message failed"
- Verifica que `SLACK_ENABLED=true`
- Verifica credenciales de Slack API
- Verifica que el canal exista
- Revisa permisos del bot de Slack

### Insights no aparecen en Supabase
- Verifica credenciales de Postgres
- Revisa logs de ejecuci√≥n en n8n
- Verifica que la tabla `insights` exista
- Comprueba permisos de inserci√≥n

## üìù Personalizaci√≥n

### Cambiar per√≠odo de an√°lisis

Edita el nodo **Prepare Dates**:
```javascript
fromDate.setDate(fromDate.getDate() - 14);  // Cambiar a 7, 30, etc.
```

### Ajustar thresholds

Configura variables de entorno:
```env
CPA_TARGET=50          # Cambiar seg√∫n tu objetivo
CTR_FATIGUE_THRESHOLD=25  # Cambiar seg√∫n tu tolerancia
```

### Cambiar modelo LLM

Edita el nodo **LLM Analyze**:
```json
{
  "model": "gpt-4o-mini"  // Cambiar a "gpt-4", "gpt-3.5-turbo", etc.
}
```

### Personalizar prompt del LLM

Edita el nodo **LLM Analyze** y ajusta el contenido del prompt seg√∫n tus necesidades.

### Agregar m√°s tipos de insights

1. Actualiza el schema de la tabla `insights`
2. Modifica el prompt del LLM para incluir nuevos tipos
3. Actualiza el nodo **Prepare Insights** para manejar nuevos tipos

## üö® Notas de Seguridad

- ‚ö†Ô∏è Protege tu `OPENAI_API_KEY`
- ‚úÖ Usa variables de entorno para todos los secrets
- ‚úÖ Valida inputs antes de procesar
- ‚úÖ Limita el tama√±o de datos enviados al LLM
- ‚úÖ Monitorea costos de OpenAI API

## üìö Recursos

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Supabase Postgres Docs](https://supabase.com/docs/guides/database)
- [Slack API Docs](https://api.slack.com/)
- [n8n Docs](https://docs.n8n.io/)

## üìÑ Archivos Incluidos

1. **n8n-workflow-insights-summarizer.json** - Workflow principal
2. **insights-table.sql** - SQL para crear tabla
3. **insights-summarizer-README.md** - Esta documentaci√≥n

## üí° Tips

- Ejecuta el workflow manualmente primero para verificar configuraci√≥n
- Monitorea los costos de OpenAI API
- Considera agregar filtros adicionales en el query si tienes muchos datos
- Usa las vistas SQL incluidas para an√°lisis r√°pido
- Implementa alertas cuando se detecten anomal√≠as cr√≠ticas

## üéØ Casos de Uso

- An√°lisis autom√°tico peri√≥dico de performance
- Detecci√≥n temprana de fatiga creativa
- Identificaci√≥n de oportunidades de optimizaci√≥n
- Alertas proactivas de anomal√≠as
- Reportes automatizados a equipos

## üìû Soporte

Si tienes problemas:
1. Revisa los logs de ejecuci√≥n en n8n
2. Verifica que todas las credenciales est√©n configuradas
3. Prueba cada nodo individualmente
4. Consulta la documentaci√≥n oficial de cada servicio

